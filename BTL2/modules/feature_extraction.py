"""
feature_extraction.py
---------------------
Module dÃ¹ng Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÄƒn báº£n (BOW, TF-IDF, Word2Vec)
vÃ  lÆ°u ra file .npy Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng sau.
"""

import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from scipy import sparse
import os


def extract_features(X_train, X_test, CONFIG):
    """
    TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« vÄƒn báº£n theo phÆ°Æ¡ng phÃ¡p embedding:
    - bow (Bag of Words)
    - tfidf (TF-IDF)
    - word2vec (Word2Vec trung bÃ¬nh)
    """
    print("ğŸ§© Äang trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vá»›i embedding =", CONFIG["embedding"])

    if CONFIG["embedding"] == "bow":
        vectorizer = CountVectorizer()
        X_train_vec = vectorizer.fit_transform(X_train)
        X_test_vec = vectorizer.transform(X_test)

    elif CONFIG["embedding"] == "tfidf":
        vectorizer = TfidfVectorizer()
        X_train_vec = vectorizer.fit_transform(X_train)
        X_test_vec = vectorizer.transform(X_test)

    elif CONFIG["embedding"] == "word2vec":
        from gensim.models import Word2Vec

        # Chuyá»ƒn text thÃ nh list tá»«
        X_train_tok = [str(x).lower().split() for x in X_train]
        X_test_tok = [str(x).lower().split() for x in X_test]

        # Huáº¥n luyá»‡n Word2Vec trÃªn dá»¯ liá»‡u train
        w2v_model = Word2Vec(
            sentences=X_train_tok, vector_size=100, window=5, min_count=1, workers=4
        )

        def get_w2v_embeddings(tokenized_texts, model, vector_size=100):
            all_embeddings = []
            for tokens in tokenized_texts:
                vectors = [model.wv[w] for w in tokens if w in model.wv]
                if len(vectors) == 0:
                    all_embeddings.append(np.zeros(vector_size))
                else:
                    all_embeddings.append(np.mean(vectors, axis=0))
            return np.vstack(all_embeddings)

        X_train_vec = get_w2v_embeddings(X_train_tok, w2v_model)
        X_test_vec = get_w2v_embeddings(X_test_tok, w2v_model)

    else:
        raise ValueError("âŒ Embedding khÃ´ng há»£p lá»‡! (bow | tfidf | word2vec)")

    print("âœ… TrÃ­ch xuáº¥t xong. Shapes:", X_train_vec.shape, X_test_vec.shape)
    return X_train_vec, X_test_vec




def save_features(X_train_vec, X_test_vec, prefix="X"):
    """
    ğŸ’¾ LÆ°u Ä‘áº·c trÆ°ng xuá»‘ng file (.npz cho sparse, .npy cho dense)
    """
    print("ğŸ’¾ Äang lÆ°u Ä‘áº·c trÆ°ng ...")

    # Táº¡o thÆ° má»¥c lÆ°u
    os.makedirs("features", exist_ok=True)

    # Táº¡o Ä‘Æ°á»ng dáº«n file
    train_path = os.path.join("features", f"{prefix}_train_vec")
    test_path = os.path.join("features", f"{prefix}_test_vec")

    # Kiá»ƒm tra dáº¡ng dá»¯ liá»‡u
    if sparse.issparse(X_train_vec):
        sparse.save_npz(train_path + ".npz", X_train_vec)
        sparse.save_npz(test_path + ".npz", X_test_vec)
        print(f"âœ… ÄÃ£ lÆ°u sparse matrix: {train_path}.npz, {test_path}.npz")
    else:
        np.save(train_path + ".npy", X_train_vec)
        np.save(test_path + ".npy", X_test_vec)
        print(f"âœ… ÄÃ£ lÆ°u dense array: {train_path}.npy, {test_path}.npy")

    print(f"ğŸ¯ Shapes khi lÆ°u: {X_train_vec.shape}, {X_test_vec.shape}")


def load_features(prefix="X"):
    """
    ğŸ“‚ Load Ä‘áº·c trÆ°ng Ä‘Ã£ lÆ°u (.npz hoáº·c .npy)
    """
    print("ğŸ“‚ Äang load láº¡i Ä‘áº·c trÆ°ng ...")

    npz_train = os.path.join("features", f"{prefix}_train_vec.npz")
    npz_test = os.path.join("features", f"{prefix}_test_vec.npz")
    npy_train = os.path.join("features", f"{prefix}_train_vec.npy")
    npy_test = os.path.join("features", f"{prefix}_test_vec.npy")

    if os.path.exists(npz_train):
        X_train_load = sparse.load_npz(npz_train)
        X_test_load = sparse.load_npz(npz_test)
        print(f"âœ… ÄÃ£ load dáº¡ng sparse (.npz): {prefix}")
    elif os.path.exists(npy_train):
        X_train_load = np.load(npy_train, allow_pickle=True)
        X_test_load = np.load(npy_test, allow_pickle=True)
        print(f"âœ… ÄÃ£ load dáº¡ng dense (.npy): {prefix}")
    else:
        raise FileNotFoundError("âŒ KhÃ´ng tÃ¬m tháº¥y file Ä‘áº·c trÆ°ng cáº§n load.")

    print("ğŸ¯ Shapes sau khi load:", X_train_load.shape, X_test_load.shape)
    return X_train_load, X_test_load
