"""
feature_extraction.py
---------------------
Module dÃ¹ng Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÄƒn báº£n (BOW, TF-IDF, Word2Vec)
vÃ  lÆ°u ra file .npy Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng sau.
"""

import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer


def extract_features(X_train, X_test, CONFIG):
    """
    TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« vÄƒn báº£n theo phÆ°Æ¡ng phÃ¡p embedding:
    - bow (Bag of Words)
    - tfidf (TF-IDF)
    - word2vec (Word2Vec trung bÃ¬nh)
    """
    print("ğŸ§© Äang trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vá»›i embedding =", CONFIG["embedding"])

    if CONFIG["embedding"] == "bow":
        vectorizer = CountVectorizer()
        X_train_vec = vectorizer.fit_transform(X_train)
        X_test_vec = vectorizer.transform(X_test)

    elif CONFIG["embedding"] == "tfidf":
        vectorizer = TfidfVectorizer()
        X_train_vec = vectorizer.fit_transform(X_train)
        X_test_vec = vectorizer.transform(X_test)

    elif CONFIG["embedding"] == "word2vec":
        from gensim.models import Word2Vec

        # Chuyá»ƒn text thÃ nh list tá»«
        X_train_tok = [str(x).lower().split() for x in X_train]
        X_test_tok = [str(x).lower().split() for x in X_test]

        # Huáº¥n luyá»‡n Word2Vec trÃªn dá»¯ liá»‡u train
        w2v_model = Word2Vec(
            sentences=X_train_tok, vector_size=100, window=5, min_count=1, workers=4
        )

        def get_w2v_embeddings(tokenized_texts, model, vector_size=100):
            all_embeddings = []
            for tokens in tokenized_texts:
                vectors = [model.wv[w] for w in tokens if w in model.wv]
                if len(vectors) == 0:
                    all_embeddings.append(np.zeros(vector_size))
                else:
                    all_embeddings.append(np.mean(vectors, axis=0))
            return np.vstack(all_embeddings)

        X_train_vec = get_w2v_embeddings(X_train_tok, w2v_model)
        X_test_vec = get_w2v_embeddings(X_test_tok, w2v_model)

    else:
        raise ValueError("âŒ Embedding khÃ´ng há»£p lá»‡! (bow | tfidf | word2vec)")

    print("âœ… TrÃ­ch xuáº¥t xong. Shapes:", X_train_vec.shape, X_test_vec.shape)
    return X_train_vec, X_test_vec


def save_features(X_train_vec, X_test_vec, prefix="X"):
    """
    LÆ°u Ä‘áº·c trÆ°ng dÆ°á»›i dáº¡ng file .npy
    """
    print("ğŸ’¾ Äang lÆ°u Ä‘áº·c trÆ°ng ...")
    np.save(f"{prefix}_train_vec.npy", X_train_vec)
    np.save(f"{prefix}_test_vec.npy", X_test_vec)
    print("âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng:", f"{prefix}_train_vec.npy", "vÃ ", f"{prefix}_test_vec.npy")


def load_features(prefix="X"):
    """
    Load Ä‘áº·c trÆ°ng tá»« file .npy
    """
    print("ğŸ“‚ Äang load láº¡i Ä‘áº·c trÆ°ng ...")
    X_train_load = np.load(f"{prefix}_train_vec.npy", allow_pickle=True)
    X_test_load = np.load(f"{prefix}_test_vec.npy", allow_pickle=True)
    print("âœ… Load xong. Shapes:", X_train_load.shape, X_test_load.shape)
    return X_train_load, X_test_load
